{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping from `datascience` to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! This notebook is an unofficial resource created by the Data Science division.\n",
    "\n",
    "It serves as an introduction to working with Python's widely used Pandas library for students who have taken data 8. The functions introduced will be analogous to those in Berkeley's `datascience` module, with examples provided for each.\n",
    "\n",
    "We will cover the following topics in this notebook:\n",
    "1. [Basics of Pandas](#basics)\n",
    "    - [Importing and Loading Packages](#import)\n",
    "<br>\n",
    "<br>\n",
    "2. [Dataframes: Working with Tabular Data](#dataframes)\n",
    "    - [Creating a Dataframe](#creating)\n",
    "    - [Accessing Values in Dataframe](#accessing)\n",
    "    - [Manipulating Data](#manipulating)\n",
    "<br>\n",
    "<br>\n",
    "3. [Visualizing Data](#visualizing)\n",
    "    - [Histograms](#histograms)\n",
    "    - [Line Plots](#line)\n",
    "    - [Scatter Plots](#scatter)\n",
    "    - [Bar Plots](#bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basics <a id='basics'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes familiarity with Python concepts, syntax and data structures at the level of Data 8. For a brief refresher on some Python concepts, refer to this [Python Basics Guide on Github](https://github.com/TiesdeKok/LearnPythonforResearch/blob/master/0_python_basics.ipynb)\n",
    "\n",
    "Python has a great ecosystem of data-centric packages which makes it excellent for data analysis. Pandas is one of those packages, and makes importing and analyzing data much easier. Pandas builds on packages like NumPy and matplotlib to give us a single, convenient, place to do most of our data analysis and visualization work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing and Loading Packages <a id='import'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to import certain packages in our workspace for analysis and data visualization. But first, we may need to install these package if they are not present already. We do this via the command line as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install datascience, pandas, and numpy packages\n",
    "!pip install datascience\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have installed the required packages, we do not need to reinstall them again when we start or reopen a Jupyter notebook. We can simply import them using the `import` keyword. Since we import Pandas as `pd`, we need to prefix all functions with `pd`, similar to how we prefix all numpy functions with `np` (such as `np.append()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the following packages\n",
    "from datascience import * # Import the datascience package\n",
    "import pandas as pd # Import the pandas library. pd is a common shorthand for pandas\n",
    "import numpy as np # Import numpy for working with numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataframes: Working with Tabular Data <a id='dataframes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python's `datascience` module, we used `Table` to build our dataframes and used commands such as `select()`, `where()`, `group()`, `column()` etc. In this section, we will go over some basic commands to work with tabular data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating a Dataframe <a id='creating'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas introduces a data structure (i.e. dataframe) that represents data as a table with columns and rows. \n",
    "\n",
    "In Python's `datascience` module that is used in Data 8, this is how we created tables from scratch by extending an empty table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Create a table\n",
    "t = Table().with_columns([\n",
    "     'letter', ['a', 'b', 'c', 'z'],\n",
    "     'count',  [  9,   3,   3,   1],\n",
    "     'points', [  1,   2,   2,  10],\n",
    " ])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use the function `pd.DataFrame` to initialize a dataframe from a dictionary or a list-like object. Refer to the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Create a dataframe from a dictionary\n",
    "df_from_dict = pd.DataFrame({ 'letter' : ['a', 'b', 'c', 'z'],\n",
    "                      'count' : [  9,   3,   3,   1],\n",
    "                      'points' : [  1,   2,   2,  10]\n",
    "                      })\n",
    "df_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More often, we will need to create a dataframe by importing data from a .csv file. In `datascience`, this is how we read data from a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Create a table from a CSV file (data/baby.csv)\n",
    "datascience_baby = Table.read_table('data/baby.csv')\n",
    "datascience_baby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `pd.read.csv()` to read data from a csv file. Sometimes, depending on the data file, we may need to specify the parameters `sep`, `header` or `encoding` as well. For a full list of parameters, refer to [this guide](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Create a dataframe from a CSV file (reading baby.csv, located in current working directory)\n",
    "baby = pd.read_csv('data/baby.csv')\n",
    "baby.head() # Display first few rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary of data\n",
    "baby.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Create a dataframe by loading CSV from URL\n",
    "# https://raw.githubusercontent.com/data-8/materials-sp18/master/lec/sat2014.csv\n",
    "sat = pd.read_csv('https://raw.githubusercontent.com/data-8/materials-sp18/master/lec/sat2014.csv')\n",
    "sat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View information about dataframe\n",
    "print(sat.shape) # View dimensions (rows, cols)\n",
    "print(sat.columns.values) # View column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Accessing Values in Dataframe <a id='accessing'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we can use `column()` to access values in a particular column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access column 'letter'. Returns array\n",
    "t.column('letter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, columns are also known as Series. We can access a Pandas series by using the square bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Return Series object\n",
    "sat['State']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a numpy array of column values, we can call the method `values` on a Series object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column values as array\n",
    "sat['State'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we used `take()` to access a row in the Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first two rows using Python's slicing notation\n",
    "t.take[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can access rows and column by their position using the `iloc` method. We need to specify the rows and columns we want in the following syntax: `df.iloc[<rows>, <columns>]`. For more information on indexing, refer to [this guide](https://pandas.pydata.org/pandas-docs/stable/indexing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first two rows using iloc\n",
    "baby.iloc[0:2, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify row indices\n",
    "baby.iloc[[1, 4, 6], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access a specific value in the dataframe by passing in the row and column indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value in second row, third column\n",
    "baby.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Manipulating Data <a id='manipulating'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding Columns**\n",
    "\n",
    "Adding a new column in `datascience` is done by the `with_column()` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Add a new column\n",
    "t.with_column('vowel', ['yes', 'no', 'no', 'no'])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use the bracket notation and assign a list to add to the dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas: Add a new column\n",
    "df_from_dict['newcol'] = [5, 6, 7, 8]\n",
    "df_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add an existing column to the new dataframe as a new column by performing an operation on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add count * 2 to the dataframe\n",
    "df_from_dict['doublecount'] = df_from_dict['count'] * 2\n",
    "df_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting Columns**\n",
    "\n",
    "In `datascience`, we used `select()` to subset the dataframe by selecting columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Select columns\n",
    "t.select(['letter', 'points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use a double bracket notation to select columns. This returns a dataframe, unlike a Series object when we only use single bracket notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Select columns (double bracket notation for new dataframe)\n",
    "df_from_dict[['count', 'doublecount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering Rows Conditionally**\n",
    "\n",
    "In `datascience`, we used `where()` to select rows according to a given condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.where('points', 2) # Rows where points == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.where(t['count'] < 8) # Rows where count < 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use the bracket notation to subset the dataframe based on a condition. We first specify a condition and then subset using the bracket notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Array of booleans\n",
    "baby['Maternal Smoker'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter rows by condition Maternal.Smoker == True\n",
    "baby[baby['Maternal Smoker'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter with multiple conditions\n",
    "df_from_dict[(df_from_dict['count'] < 8) & (df_from_dict['points'] > 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming Columns**\n",
    "\n",
    "In `datascience`, we used `relabeled()` to rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Rename 'points' to 'other name'\n",
    "t.relabeled('points', 'other name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses `rename()`, which has an `index` parameter that needs to be set to `str` and a `columns` parameter that needs to be set to a dictionary of the names to be replaced with their replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Rename 'points' to 'other name'\n",
    "df_from_dict.rename(index = str, columns = {\"points\" : \"other name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting Dataframe by Column**\n",
    "\n",
    "In `datascience` we used `sort()` to sort a Table according to the values in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Sort by count\n",
    "t.sort('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use the `sort_values()` to sort by column. We need the `by` parameter to specify the row we want to sort by and the optional parameter `ascending = False` if we want to sort in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas: Sort by count, descending\n",
    "df_from_dict.sort_values(by = ['count'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping and Aggregating**\n",
    "\n",
    "In `datascience`, we used `group()` and the `collect` argument to group a Table by a column and aggregrate values in another column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Group by count and aggregate by sum\n",
    "t.select(['count', 'points']).group('count', collect=sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `groupby()` to group the dataframe. This function returns a groupby object, on which we can then call an aggregation function to return a dataframe with aggregated values for other columns. For more information, refer to the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two columns for brevity\n",
    "df_subset = df_from_dict[['count', 'points']]\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Group by count and aggregate by sum\n",
    "count_sums_df = df_subset.groupby(['count']).sum()\n",
    "count_sums_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivot Tables**\n",
    "\n",
    "In `datascience`, we used the `pivot()` function to build contingency tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Create new table\n",
    "cones_tbl = Table().with_columns(\n",
    "    'Flavor', make_array('strawberry', 'chocolate', 'chocolate', 'strawberry', 'chocolate', 'bubblegum'),\n",
    "    'Color', make_array('pink', 'light brown', 'dark brown', 'pink', 'dark brown', 'pink'),\n",
    "    'Price', make_array(3.55, 4.75, 5.25, 5.25, 5.25, 4.75)\n",
    ")\n",
    "\n",
    "cones_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pivot on color and flavor\n",
    "cones_tbl.pivot(\"Flavor\", \"Color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in the parameters `values` to specify the values in the table and `collect` to specify the aggregration function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters values and collect\n",
    "cones_tbl.pivot(\"Flavor\", \"Color\", values = \"Price\", collect = np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `pd.pivot_table()` to create a contingency table. The argument `columns` is similar to the first argument in `datascience`'s `pivot` function and sets the column names of the pivot table. The argument `index` is similar to the second argument in `datascience`'s `pivot` function and sets the first column of the pivot table or the keys to group on. For more information, refer to the [documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Create new dataframe\n",
    "cones_df = pd.DataFrame({\"Flavor\" : ['strawberry', 'chocolate', 'chocolate', 'strawberry', 'chocolate', 'bubblegum'],\n",
    "                         \"Color\" : ['pink', 'light brown', 'dark brown', 'pink', 'dark brown', 'pink'],\n",
    "                         \"Price\" : [3.55, 4.75, 5.25, 5.25, 5.25, 4.75]})\n",
    "cones_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pivot table\n",
    "pd.pivot_table(cones_df, columns = [\"Flavor\"], index = [\"Color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no data in the groups, then Pandas will output `NaN` values. \n",
    "\n",
    "We can also specify the parameters like `values` (equivalent to `values` in `datascience`'s `pivot`) and `aggfunc` (equivalent to `collect` in `datascience`'s `pivot`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional arguments\n",
    "pd.pivot_table(cones_df, columns = [\"Flavor\"], index = [\"Color\"], values = \"Price\", aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joining/Merging**\n",
    "\n",
    "In `datascience`, we used `join()` to join two tables based on shared values in columns. We specify the column name in the first table to match on, the name of the second table and the column name in the second table to match on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Create new table\n",
    "ratings_tbl = Table().with_columns(\n",
    "    'Kind', make_array('strawberry', 'chocolate', 'vanilla'),\n",
    "    'Stars', make_array(2.5, 3.5, 4)\n",
    ")\n",
    "ratings_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join cones and ratings\n",
    "cones_tbl.join(\"Flavor\", ratings_tbl, \"Kind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use the `merge()` function to join two tables together. The first parameter is the name of the second table to join on. The parameters `left_on` and `right_on` specify the columns to use in the left and right tables respectively. There are more parameters such as `how` which specify what kind of join to perform (Inner (Default), Outer, Left, Right). For more information, refer to this [Kaggle Tutorial](https://www.kaggle.com/crawford/python-merge-tutorial/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Create new ratings df\n",
    "ratings_df = pd.DataFrame({\"Kind\" : ['strawberry', 'chocolate', 'vanilla'],\n",
    "                           \"Stars\" : [2.5, 3.5, 4]})\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cones and ratings\n",
    "cones_df.merge(ratings_df, left_on = \"Flavor\", right_on = \"Kind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing Data <a id='visualizing'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we learned to plot data using histograms, line plots, scatter plots and histograms. The corresponding functions were `hist()`, `plot()`, `scatter()` and `barh()`. Plotting methods in Pandas are nearly identical to `datascience` since both build on the library `matplotlib`\n",
    "\n",
    "In this section we will go through examples of such plots in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='histograms'></a>**3.1 Histograms**\n",
    "\n",
    "In `datascience`, we used `hist()` to create a histogram. In this example, we will be using data from `baby.csv`. Recall that the baby data set contains data on a random sample of 1,174 mothers and their newborn babies. The column `Birth.Weight` contains the birth weight of the baby, in ounces; `Gestational.Days` is the number of gestational days, that is, the number of days the baby was in the womb. There is also data on maternal age, maternal height, maternal pregnancy weight, and whether or not the mother was a smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Read in the data (data/baby.csv)\n",
    "datascience_baby = Table.read_table('data/baby.csv')\n",
    "datascience_baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Create a histogram\n",
    "datascience_baby.hist('Birth Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `hist()` to create histograms, just like `datascience`. Refer to the [documentation](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.hist.html) for a full list of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Create a histogram\n",
    "baby.hist('Birth Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='line'></a>**3.2 Line Plots**\n",
    "\n",
    "In `datascience`, we used `plot()` to create a line plot of numerical values. In this example, we will be using census data and plot variables such as Age in a line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Line plot\n",
    "# https://raw.githubusercontent.com/data-8/materials-x18/master/lec/x18/1/census.csv\n",
    "census_tbl = Table.read_table(\"https://raw.githubusercontent.com/data-8/materials-x18/master/lec/x18/1/census.csv\").select(['SEX', 'AGE', 'POPESTIMATE2014'])\n",
    "children_tbl = census_tbl.where('SEX', are.equal_to(0)).where('AGE', are.below(19)).drop('SEX')\n",
    "children_tbl.plot('AGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use `plot.line()` to create line plots. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.line.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Line plot\n",
    "# https://raw.githubusercontent.com/data-8/materials-x18/master/lec/x18/1/census.csv\n",
    "census_df = pd.read_csv(\"https://raw.githubusercontent.com/data-8/materials-x18/master/lec/x18/1/census.csv\")[[\"SEX\", \"AGE\", \"POPESTIMATE2014\"]]\n",
    "children_df = census_df[(census_df.SEX == 0) & (census_df.AGE < 19)].drop(\"SEX\", axis=1)\n",
    "children_df.plot.line(x=\"AGE\", y=\"POPESTIMATE2014\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scatter'></a>**3.3 Scatter Plots**\n",
    "\n",
    "In `datascience`, we used `scatter()` to create a scatter plot of two numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Read in the data\n",
    "# https://raw.githubusercontent.com/data-8/materials-sp18/master/lec/deflategate.csv\n",
    "football_tbl = Table.read_table('https://raw.githubusercontent.com/data-8/materials-sp18/master/lec/deflategate.csv')\n",
    "football_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Scatter plot\n",
    "football_tbl.scatter('Blakeman', 'Prioleau')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `plot.scatter()` to create a scatter plot. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.scatter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Read in the data\n",
    "# https://raw.githubusercontent.com/data-8/materials-sp18/master/lec/deflategate.csv\n",
    "football_df = pd.read_csv('https://raw.githubusercontent.com/data-8/materials-sp18/master/lec/deflategate.csv')\n",
    "# pandas: Scatter plot\n",
    "football_df.plot.scatter(x=\"Blakeman\", y=\"Prioleau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bar'></a>**3.4 Bar Plots**\n",
    "\n",
    "In `datascience`, we used `barh()` to create a horizontal bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datascience: Horizontal bar chart\n",
    "t.barh(\"letter\", \"points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `plot.barh()` to create a bar chart. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.barh.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Horizontal bar chart\n",
    "df_from_dict.plot.barh(x='letter', y='points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "Here is a list of useful Pandas resources:\n",
    "\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [Dataquest Pandas Tutorial](https://www.dataquest.io/blog/pandas-python-tutorial/)\n",
    "- [Pandas Cookbook](http://nbviewer.jupyter.org/github/jvns/pandas-cookbook/tree/master/cookbook/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
